{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "from scipy.stats import norm\n",
    "#from pyglmnet import GLM # Marco: need to understand how to install this \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from subprocess import call\n",
    "from sklearn.cross_validation import KFold\n",
    "#from sklearn.model_selection import KFold\n",
    "\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Ensemble class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    def __init__(self, n_folds, base_models,seed_value):\n",
    "        self.n_folds = n_folds\n",
    "        self.base_models = base_models\n",
    "        self.seed_value = seed_value\n",
    "        \n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "        \n",
    "        folds = list(KFold(len(y), n_folds=self.n_folds, shuffle=True, random_state=self.seed_value))\n",
    "        #folds = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.seed_value)\n",
    "        \n",
    "        print(\"folds=\",folds)\n",
    "        \n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, reg in enumerate(self.base_models):\n",
    "            S_test_i = np.zeros((T.shape[0], len(folds)))\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                # y_holdout = y[test_idx]\n",
    "                reg.fit(X_train, y_train)\n",
    "                y_pred = reg.predict(X_holdout)[:]\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = reg.predict(T)[:]\n",
    "            S_test[:, i] = S_test_i.mean(1)\n",
    "        \n",
    "        '''\n",
    "        # Cross validate the stacker model\n",
    "        stackermodel = xgb.XGBRegressor()\n",
    "\n",
    "        # dict with tunning parameters\n",
    "        param_grid = {\n",
    "        'max_depth': [2, 4], \n",
    "        'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        'min_child_weight': range(1, 10, 2),\n",
    "        'n_estimators': range(50, 300, 50),\n",
    "        'objective': ['reg:linear']\n",
    "        }\n",
    "\n",
    "        #kfold = KFold(n_splits=nfold, random_state=seed)\n",
    "\n",
    "        scorer = make_scorer(rmse, greater_is_better=False)\n",
    "        grid_search = GridSearchCV(stackermodel, param_grid, n_jobs=-1, cv=5, verbose=1, scoring=scorer)\n",
    "        grid_result = grid_search.fit(S_train, y)\n",
    "\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "        for mean, stdev, param in zip(means, stds, params):\n",
    "        #print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "            print(\"{:06.5f} ({:06.5f}) with {}\".format(mean, stdev, param))\n",
    "\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        '''\n",
    "        # Now fit the stacker model\n",
    "        stackermodel = xgb.XGBRegressor(n_estimators=100,learning_rate=0.1,max_depth=2,min_child_weight=5,objective='reg:linear')\n",
    "        stackermodel.fit(S_train, y)\n",
    "        y_pred = stackermodel.predict(S_test)[:]\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../models/single/model_elasticnet.py\n",
      "../../models/single/model_et.py\n",
      "../../models/single/model_lgb.py\n",
      "../../models/single/model_rf.py\n",
      "../../models/single/model_xgb.py\n",
      "['../../models/single/model_elasticnet.py', '../../models/single/model_et.py', '../../models/single/model_lgb.py', '../../models/single/model_rf.py', '../../models/single/model_xgb.py']\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "seed = 2017\n",
    "nfold = 5\n",
    "bmodels = [\"elasticnet\",\"et\",\"lgb\",\"rf\",\"xgb\"]\n",
    "    \n",
    "train = pd.read_csv(\"../../data/X_train_v2.csv\")\n",
    "y = train['SalePrice']\n",
    "X = train.loc[:,'MSSubClass':'SaleCondition_Partial']\n",
    "    \n",
    "test = pd.read_csv(\"../../data/X_test_v2.csv\")\n",
    "id = test[\"Id\"]\n",
    "T = test.loc[:,'MSSubClass':'SaleCondition_Partial']\n",
    "    \n",
    "#Set the base models\n",
    "\n",
    "base_models_name = []\n",
    "for j in range(len(bmodels)):\n",
    "        modelname = (\"../../models/single/model_\" + bmodels[j] + \".py\")\n",
    "        print(modelname)\n",
    "        base_models_name.append(modelname)\n",
    "\n",
    "print(base_models_name)\n",
    "base_models = []\n",
    "    \n",
    "for i, bm in enumerate(base_models_name):\n",
    "        model = !grep \"model =\" {bm}\n",
    "        model = model[0]\n",
    "        model = model[12:]\n",
    "        model = eval(model)\n",
    "        base_models.append(model)\n",
    "#print(model)\n",
    "#print(base_models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#xgb = xgb.XGBRegressor(n_estimators=250,learning_rate=0.1,max_depth=4,min_child_weight=1,objective='reg:linear')\n",
    "# Call stacking\n",
    "    \n",
    "ens = Ensemble(n_folds=nfold, base_models=base_models,seed_value=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folds= [(array([   0,    1,    2, ..., 1436, 1437, 1438]), array([  17,   20,   25,   41,   54,   55,   56,   57,   61,   64,   93,\n",
      "        100,  102,  114,  115,  116,  117,  119,  120,  123,  128,  160,\n",
      "        166,  168,  179,  183,  188,  189,  191,  192,  196,  213,  216,\n",
      "        222,  230,  232,  235,  238,  239,  243,  257,  261,  262,  263,\n",
      "        270,  271,  273,  277,  282,  296,  299,  300,  313,  317,  319,\n",
      "        331,  332,  333,  350,  353,  356,  358,  364,  371,  374,  375,\n",
      "        377,  379,  383,  389,  391,  397,  401,  411,  413,  414,  416,\n",
      "        421,  423,  426,  433,  434,  435,  436,  441,  443,  449,  451,\n",
      "        457,  460,  461,  462,  463,  464,  465,  478,  480,  481,  484,\n",
      "        487,  492,  497,  499,  505,  510,  522,  530,  534,  536,  539,\n",
      "        544,  546,  554,  555,  556,  557,  570,  571,  575,  577,  601,\n",
      "        609,  617,  623,  636,  639,  642,  649,  650,  651,  652,  657,\n",
      "        668,  679,  681,  684,  692,  698,  701,  714,  717,  718,  723,\n",
      "        727,  735,  737,  738,  749,  751,  759,  764,  779,  780,  792,\n",
      "        795,  798,  800,  806,  812,  828,  835,  838,  843,  856,  861,\n",
      "        867,  868,  869,  873,  875,  876,  879,  880,  887,  892,  893,\n",
      "        912,  918,  934,  936,  944,  946,  950,  952,  955,  982,  983,\n",
      "        987,  988,  991,  993,  997,  998, 1004, 1009, 1012, 1018, 1024,\n",
      "       1025, 1026, 1028, 1030, 1037, 1043, 1045, 1054, 1055, 1056, 1059,\n",
      "       1065, 1068, 1087, 1089, 1091, 1092, 1104, 1108, 1113, 1115, 1116,\n",
      "       1122, 1134, 1140, 1142, 1152, 1160, 1175, 1177, 1180, 1186, 1190,\n",
      "       1192, 1194, 1199, 1201, 1203, 1213, 1215, 1217, 1218, 1231, 1232,\n",
      "       1237, 1253, 1254, 1259, 1264, 1269, 1272, 1281, 1285, 1292, 1295,\n",
      "       1299, 1300, 1302, 1305, 1306, 1311, 1316, 1320, 1322, 1324, 1325,\n",
      "       1337, 1342, 1344, 1348, 1349, 1353, 1354, 1357, 1371, 1373, 1382,\n",
      "       1385, 1392, 1398, 1407, 1408, 1410, 1411, 1412, 1415, 1425, 1428,\n",
      "       1430, 1435])), (array([   2,    3,    4, ..., 1436, 1437, 1438]), array([   0,    1,    5,   11,   15,   18,   21,   30,   33,   36,   42,\n",
      "         59,   60,   63,   67,   72,   76,   78,   81,   82,   86,   94,\n",
      "         97,  104,  106,  108,  111,  121,  134,  138,  140,  148,  149,\n",
      "        150,  155,  157,  161,  162,  165,  174,  181,  186,  190,  194,\n",
      "        197,  202,  206,  207,  211,  214,  218,  219,  221,  237,  241,\n",
      "        247,  249,  259,  285,  287,  288,  308,  311,  312,  314,  323,\n",
      "        324,  336,  340,  347,  351,  355,  360,  361,  362,  363,  368,\n",
      "        381,  382,  387,  390,  396,  399,  400,  402,  417,  420,  429,\n",
      "        430,  432,  438,  452,  467,  472,  473,  476,  482,  485,  501,\n",
      "        503,  509,  512,  516,  517,  523,  538,  548,  550,  551,  552,\n",
      "        558,  561,  562,  563,  580,  585,  597,  603,  605,  618,  621,\n",
      "        624,  625,  632,  635,  638,  640,  644,  647,  656,  662,  665,\n",
      "        687,  690,  693,  697,  706,  710,  712,  726,  728,  733,  734,\n",
      "        742,  744,  747,  757,  758,  763,  765,  766,  773,  776,  777,\n",
      "        783,  787,  788,  791,  794,  809,  811,  818,  819,  821,  829,\n",
      "        830,  833,  837,  842,  849,  853,  857,  864,  866,  870,  890,\n",
      "        891,  905,  907,  908,  914,  917,  920,  922,  923,  927,  931,\n",
      "        932,  937,  938,  941,  943,  962,  963,  981,  986,  999, 1000,\n",
      "       1005, 1008, 1014, 1015, 1017, 1020, 1029, 1032, 1033, 1034, 1035,\n",
      "       1038, 1044, 1046, 1060, 1063, 1069, 1075, 1085, 1086, 1090, 1096,\n",
      "       1099, 1100, 1101, 1103, 1105, 1120, 1125, 1138, 1144, 1146, 1150,\n",
      "       1165, 1166, 1172, 1174, 1176, 1178, 1179, 1181, 1182, 1184, 1187,\n",
      "       1189, 1204, 1205, 1207, 1212, 1219, 1223, 1227, 1230, 1248, 1256,\n",
      "       1258, 1262, 1265, 1268, 1271, 1280, 1282, 1286, 1289, 1291, 1293,\n",
      "       1296, 1321, 1330, 1335, 1340, 1341, 1345, 1355, 1358, 1363, 1365,\n",
      "       1370, 1372, 1379, 1384, 1386, 1387, 1388, 1391, 1394, 1396, 1404,\n",
      "       1421, 1424])), (array([   0,    1,    2, ..., 1434, 1435, 1437]), array([   7,   10,   12,   19,   24,   27,   32,   34,   40,   43,   44,\n",
      "         45,   48,   50,   52,   53,   62,   71,   84,   89,   92,   95,\n",
      "         96,   98,  101,  107,  118,  129,  132,  133,  136,  139,  145,\n",
      "        146,  147,  151,  154,  159,  163,  164,  170,  173,  177,  182,\n",
      "        184,  185,  187,  201,  210,  217,  226,  227,  229,  233,  236,\n",
      "        242,  245,  246,  250,  253,  254,  266,  267,  278,  281,  283,\n",
      "        289,  290,  293,  304,  305,  306,  310,  322,  326,  327,  329,\n",
      "        335,  339,  367,  369,  370,  376,  403,  405,  407,  412,  422,\n",
      "        428,  437,  440,  442,  446,  455,  458,  468,  486,  488,  493,\n",
      "        496,  498,  500,  502,  504,  507,  515,  520,  526,  527,  528,\n",
      "        532,  533,  535,  540,  545,  553,  564,  567,  569,  572,  573,\n",
      "        576,  578,  581,  583,  584,  586,  588,  595,  598,  602,  604,\n",
      "        611,  615,  622,  630,  637,  641,  648,  655,  660,  663,  667,\n",
      "        669,  672,  674,  677,  694,  702,  708,  709,  715,  720,  721,\n",
      "        732,  736,  741,  743,  745,  746,  748,  750,  755,  756,  761,\n",
      "        762,  767,  768,  769,  772,  774,  775,  789,  796,  797,  803,\n",
      "        810,  815,  816,  820,  824,  826,  834,  839,  845,  846,  847,\n",
      "        851,  852,  859,  881,  882,  884,  897,  904,  913,  925,  942,\n",
      "        961,  969,  980,  984,  989,  994,  995, 1003, 1019, 1027, 1031,\n",
      "       1042, 1048, 1049, 1057, 1061, 1066, 1067, 1071, 1072, 1074, 1077,\n",
      "       1082, 1083, 1102, 1109, 1117, 1119, 1121, 1123, 1124, 1135, 1136,\n",
      "       1139, 1143, 1145, 1153, 1154, 1162, 1164, 1168, 1170, 1188, 1193,\n",
      "       1197, 1202, 1209, 1211, 1220, 1221, 1228, 1233, 1234, 1239, 1242,\n",
      "       1244, 1247, 1250, 1255, 1261, 1263, 1270, 1277, 1279, 1294, 1297,\n",
      "       1298, 1307, 1309, 1315, 1326, 1327, 1329, 1338, 1343, 1347, 1359,\n",
      "       1369, 1375, 1377, 1380, 1389, 1390, 1395, 1401, 1405, 1419, 1433,\n",
      "       1436, 1438])), (array([   0,    1,    4, ..., 1435, 1436, 1438]), array([   2,    3,   23,   26,   31,   37,   38,   39,   69,   73,   74,\n",
      "         77,   79,   83,   87,   91,   99,  105,  113,  124,  125,  127,\n",
      "        131,  137,  141,  142,  144,  152,  153,  156,  158,  171,  175,\n",
      "        176,  205,  209,  215,  225,  228,  231,  234,  244,  248,  251,\n",
      "        258,  260,  265,  268,  275,  279,  286,  291,  292,  297,  298,\n",
      "        301,  303,  315,  316,  318,  328,  330,  337,  338,  341,  343,\n",
      "        346,  348,  354,  357,  359,  365,  366,  372,  373,  380,  386,\n",
      "        388,  393,  406,  409,  410,  415,  418,  425,  431,  439,  445,\n",
      "        448,  453,  454,  469,  474,  479,  489,  508,  513,  518,  521,\n",
      "        531,  537,  542,  543,  560,  565,  566,  574,  589,  590,  593,\n",
      "        600,  610,  612,  619,  626,  628,  633,  634,  645,  654,  658,\n",
      "        659,  664,  666,  670,  673,  678,  680,  682,  683,  685,  689,\n",
      "        691,  695,  699,  700,  705,  711,  713,  716,  719,  724,  730,\n",
      "        731,  740,  752,  754,  770,  782,  785,  793,  799,  801,  805,\n",
      "        807,  813,  814,  823,  825,  827,  836,  840,  841,  848,  850,\n",
      "        855,  862,  863,  878,  883,  885,  888,  889,  898,  899,  901,\n",
      "        902,  903,  910,  921,  924,  929,  933,  945,  951,  954,  956,\n",
      "        960,  964,  966,  970,  973,  974,  975,  977,  985, 1006, 1007,\n",
      "       1010, 1013, 1016, 1021, 1023, 1040, 1047, 1050, 1051, 1053, 1076,\n",
      "       1079, 1080, 1081, 1084, 1088, 1097, 1107, 1110, 1111, 1112, 1114,\n",
      "       1126, 1128, 1137, 1141, 1147, 1149, 1151, 1155, 1156, 1157, 1158,\n",
      "       1159, 1163, 1169, 1173, 1183, 1185, 1198, 1200, 1206, 1208, 1210,\n",
      "       1216, 1226, 1229, 1236, 1238, 1243, 1245, 1249, 1251, 1257, 1260,\n",
      "       1266, 1267, 1283, 1284, 1287, 1288, 1290, 1303, 1310, 1314, 1317,\n",
      "       1323, 1328, 1331, 1332, 1346, 1350, 1352, 1356, 1360, 1364, 1367,\n",
      "       1378, 1381, 1393, 1400, 1409, 1413, 1414, 1416, 1420, 1423, 1432,\n",
      "       1434, 1437])), (array([   0,    1,    2, ..., 1436, 1437, 1438]), array([   4,    6,    8,    9,   13,   14,   16,   22,   28,   29,   35,\n",
      "         46,   47,   49,   51,   58,   65,   66,   68,   70,   75,   80,\n",
      "         85,   88,   90,  103,  109,  110,  112,  122,  126,  130,  135,\n",
      "        143,  167,  169,  172,  178,  180,  193,  195,  198,  199,  200,\n",
      "        203,  204,  208,  212,  220,  223,  224,  240,  252,  255,  256,\n",
      "        264,  269,  272,  274,  276,  280,  284,  294,  295,  302,  307,\n",
      "        309,  320,  321,  325,  334,  342,  344,  345,  349,  352,  378,\n",
      "        384,  385,  392,  394,  395,  398,  404,  408,  419,  424,  427,\n",
      "        444,  447,  450,  456,  459,  466,  470,  471,  475,  477,  483,\n",
      "        490,  491,  494,  495,  506,  511,  514,  519,  524,  525,  529,\n",
      "        541,  547,  549,  559,  568,  579,  582,  587,  591,  592,  594,\n",
      "        596,  599,  606,  607,  608,  613,  614,  616,  620,  627,  629,\n",
      "        631,  643,  646,  653,  661,  671,  675,  676,  686,  688,  696,\n",
      "        703,  704,  707,  722,  725,  729,  739,  753,  760,  771,  778,\n",
      "        781,  784,  786,  790,  802,  804,  808,  817,  822,  831,  832,\n",
      "        844,  854,  858,  860,  865,  871,  872,  874,  877,  886,  894,\n",
      "        895,  896,  900,  906,  909,  911,  915,  916,  919,  926,  928,\n",
      "        930,  935,  939,  940,  947,  948,  949,  953,  957,  958,  959,\n",
      "        965,  967,  968,  971,  972,  976,  978,  979,  990,  992,  996,\n",
      "       1001, 1002, 1011, 1022, 1036, 1039, 1041, 1052, 1058, 1062, 1064,\n",
      "       1070, 1073, 1078, 1093, 1094, 1095, 1098, 1106, 1118, 1127, 1129,\n",
      "       1130, 1131, 1132, 1133, 1148, 1161, 1167, 1171, 1191, 1195, 1196,\n",
      "       1214, 1222, 1224, 1225, 1235, 1240, 1241, 1246, 1252, 1273, 1274,\n",
      "       1275, 1276, 1278, 1301, 1304, 1308, 1312, 1313, 1318, 1319, 1333,\n",
      "       1334, 1336, 1339, 1351, 1361, 1362, 1366, 1368, 1374, 1376, 1383,\n",
      "       1397, 1399, 1402, 1403, 1406, 1417, 1418, 1422, 1426, 1427, 1429,\n",
      "       1431]))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obaidur/software/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results= [ 11.70666027  11.99262905  12.1004324  ...,  12.02122307  11.69092369\n",
      "  12.34872532]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "results = ens.fit_predict(X,y,T)\n",
    "print(\"results=\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = np.expm1(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results= [ 121376.4375     161558.546875   179948.65625   ...,  166244.859375\n",
      "  119481.3203125  230664.828125 ]\n",
      "results=         Id      SalePrice\n",
      "0     1461  121376.437500\n",
      "1     1462  161558.546875\n",
      "2     1463  179948.656250\n",
      "3     1464  191589.484375\n",
      "4     1465  186012.671875\n",
      "5     1466  166515.875000\n",
      "6     1467  176829.640625\n",
      "7     1468  161645.312500\n",
      "8     1469  179948.656250\n",
      "9     1470  121856.835938\n",
      "10    1471  188974.031250\n",
      "11    1472   96286.414062\n",
      "12    1473   94331.070312\n",
      "13    1474  143913.562500\n",
      "14    1475  108637.726562\n",
      "15    1476  400335.093750\n",
      "16    1477  245365.468750\n",
      "17    1478  293802.593750\n",
      "18    1479  290534.531250\n",
      "19    1480  543254.812500\n",
      "20    1481  333779.500000\n",
      "21    1482  207804.750000\n",
      "22    1483  175863.968750\n",
      "23    1484  161645.312500\n",
      "24    1485  189562.109375\n",
      "25    1486  192817.781250\n",
      "26    1487  340901.000000\n",
      "27    1488  231242.562500\n",
      "28    1489  195015.890625\n",
      "29    1490  225162.500000\n",
      "...    ...            ...\n",
      "1429  2890   82281.914062\n",
      "1430  2891  133769.843750\n",
      "1431  2892   42387.871094\n",
      "1432  2893   68097.195312\n",
      "1433  2894   42387.871094\n",
      "1434  2895  338523.343750\n",
      "1435  2896  293802.593750\n",
      "1436  2897  205853.375000\n",
      "1437  2898  149373.125000\n",
      "1438  2899  213281.406250\n",
      "1439  2900  161382.218750\n",
      "1440  2901  191749.437500\n",
      "1441  2902  183525.140625\n",
      "1442  2903  329254.687500\n",
      "1443  2904  345585.875000\n",
      "1444  2905   78744.867188\n",
      "1445  2906  197831.343750\n",
      "1446  2907  114082.265625\n",
      "1447  2908  128293.664062\n",
      "1448  2909  146776.234375\n",
      "1449  2910   70394.882812\n",
      "1450  2911   86533.750000\n",
      "1451  2912  150754.593750\n",
      "1452  2913   86533.750000\n",
      "1453  2914   79189.570312\n",
      "1454  2915   86533.750000\n",
      "1455  2916   86533.750000\n",
      "1456  2917  166244.859375\n",
      "1457  2918  119481.320312\n",
      "1458  2919  230664.828125\n",
      "\n",
      "[1459 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"results=\",results)\n",
    "results = pd.DataFrame(results)\n",
    "results = pd.concat([id,results], axis=1)\n",
    "results.columns =[\"Id\",\"SalePrice\"]\n",
    "print(\"results=\",results)\n",
    "results.to_csv(\"./ensembled_results.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
